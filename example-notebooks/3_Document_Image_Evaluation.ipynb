{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5eede525-22f2-4e25-874e-e6be4ba13d50",
   "metadata": {},
   "source": [
    "# Overview\n",
    "This notebook demonstrates how to evaluate RAG systems on documents containing images, charts, tables, and other visual elements. Most enterprise documents contain critical information in visual formats that pure text-based RAG systems miss entirely.\n",
    "\n",
    "# Background\n",
    "Traditional RAG evaluation focuses on clean text documents, but real-world enterprise documents are complex:\n",
    "- Financial reports with embedded charts and tables\n",
    "- Technical manuals with diagrams and flowcharts  \n",
    "- Research papers with data visualizations\n",
    "- Forms and structured documents\n",
    "\n",
    "This notebook bridges the gap between research and reality by evaluating how well RAG systems handle documents with visual content.\n",
    "\n",
    "**What Metrics Should You Care About?**\n",
    "- **Visual Content Recall**: How many relevant charts/tables are retrieved?\n",
    "- **OCR Quality Impact**: How do extraction errors affect retrieval?\n",
    "- **Completeness Improvement**: Are answers more complete with visual content?\n",
    "- **Cost vs Quality**: ROI analysis of different OCR approaches\n",
    "\n",
    "# What Will We Do? \n",
    "* Process PDF documents with embedded images/tables using AWS Textract\n",
    "* Create evaluation dataset with visual-heavy documents\n",
    "* Compare retrieval performance: text-only vs text+visual\n",
    "* Measure OCR quality impact on retrieval accuracy\n",
    "* Analyze cost-benefit of multi-modal RAG\n",
    "\n",
    "**Let's get started!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7929a338-d85a-405d-8cc7-e33a12dd9bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All clients initialized successfully\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import io\n",
    "import base64\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "from pydantic import BaseModel\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from PIL import Image\n",
    "import tempfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Initialize clients\n",
    "session = boto3.Session(profile_name='default')\n",
    "bedrock_client = boto3.client('bedrock-runtime')\n",
    "textract_client = boto3.client('textract')\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "# Initialize Chroma client\n",
    "chroma_client = chromadb.PersistentClient(path=\"../data/chroma\")\n",
    "\n",
    "print(\"All clients initialized successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529a27af-60cd-46b2-8f34-1c45ae6d10b5",
   "metadata": {},
   "source": [
    "# Document Processing Pipeline\n",
    "\n",
    "We'll create a comprehensive pipeline that can handle various document types and extract both text and visual content using AWS Textract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b54a7676-08b8-4c6a-9545-2d6e9165ad19",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'genaisystemevaluationmediatestbucket' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 165\u001b[39m\n\u001b[32m    153\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m EnrichedChunk(\n\u001b[32m    154\u001b[39m                 id_=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_error\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    155\u001b[39m                 text_content=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError processing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    159\u001b[39m                 metadata={\u001b[33m'\u001b[39m\u001b[33msource_file\u001b[39m\u001b[33m'\u001b[39m: file_name, \u001b[33m'\u001b[39m\u001b[33merror\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mstr\u001b[39m(e)}\n\u001b[32m    160\u001b[39m             )\n\u001b[32m    162\u001b[39m \u001b[38;5;66;03m# Initialize the processor\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[38;5;66;03m# Note: Set your S3 bucket name here for full Textract functionality\u001b[39;00m\n\u001b[32m    164\u001b[39m \u001b[38;5;66;03m#S3_BUCKET_NAME = None  # Replace with your bucket name: \"your-textract-bucket\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m S3_BUCKET_NAME = \u001b[43mgenaisystemevaluationmediatestbucket\u001b[49m\n\u001b[32m    167\u001b[39m doc_processor = MultiModalDocumentProcessor(\n\u001b[32m    168\u001b[39m     textract_client=textract_client,\n\u001b[32m    169\u001b[39m     s3_client=s3_client,\n\u001b[32m    170\u001b[39m     bucket_name=S3_BUCKET_NAME\n\u001b[32m    171\u001b[39m )\n\u001b[32m    173\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✅ Document processing pipeline initialized\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'genaisystemevaluationmediatestbucket' is not defined"
     ]
    }
   ],
   "source": [
    "class VisualContent(BaseModel):\n",
    "    content_type: str  # \"table\", \"key_value\", \"text\", \"form\"\n",
    "    content: str       # The extracted/formatted content\n",
    "    confidence: float  # OCR confidence score\n",
    "    bounding_box: Dict # Location in document\n",
    "    metadata: Dict = {}\n",
    "\n",
    "class EnrichedChunk(BaseModel):\n",
    "    id_: str\n",
    "    text_content: str\n",
    "    visual_content: List[VisualContent] = []\n",
    "    document_type: str  # \"financial_report\", \"technical_manual\", etc.\n",
    "    has_visual_elements: bool = False\n",
    "    metadata: Dict[str, Any] = {}\n",
    "\n",
    "class MultiModalDocumentProcessor:\n",
    "    def __init__(self, textract_client, s3_client, bucket_name: str = None):\n",
    "        self.textract_client = textract_client\n",
    "        self.s3_client = s3_client\n",
    "        self.bucket_name = bucket_name\n",
    "    \n",
    "    def upload_to_s3(self, file_path: str, s3_key: str) -> str:\n",
    "        \"\"\"Upload file to S3 for Textract processing\"\"\"\n",
    "        if not self.bucket_name:\n",
    "            raise ValueError(\"S3 bucket name required for Textract processing\")\n",
    "        \n",
    "        self.s3_client.upload_file(file_path, self.bucket_name, s3_key)\n",
    "        return s3_key\n",
    "    \n",
    "    def extract_with_textract(self, s3_key: str) -> Dict:\n",
    "        \"\"\"Extract text, tables, and forms using AWS Textract\"\"\"\n",
    "        try:\n",
    "            response = self.textract_client.analyze_document(\n",
    "                Document={\n",
    "                    'S3Object': {\n",
    "                        'Bucket': self.bucket_name,\n",
    "                        'Name': s3_key\n",
    "                    }\n",
    "                },\n",
    "                FeatureTypes=['TABLES', 'FORMS']\n",
    "            )\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            print(f\"Textract extraction failed: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def parse_textract_response(self, response: Dict) -> Tuple[str, List[VisualContent]]:\n",
    "        \"\"\"Parse Textract response into text and visual content\"\"\"\n",
    "        if not response:\n",
    "            return \"\", []\n",
    "        \n",
    "        blocks = response.get('Blocks', [])\n",
    "        \n",
    "        # Extract text blocks\n",
    "        text_blocks = []\n",
    "        visual_content = []\n",
    "        \n",
    "        for block in blocks:\n",
    "            if block['BlockType'] == 'LINE':\n",
    "                text_blocks.append(block.get('Text', ''))\n",
    "            \n",
    "            elif block['BlockType'] == 'TABLE':\n",
    "                table_content = self.extract_table_content(block, blocks)\n",
    "                visual_content.append(VisualContent(\n",
    "                    content_type=\"table\",\n",
    "                    content=table_content,\n",
    "                    confidence=block.get('Confidence', 0),\n",
    "                    bounding_box=block.get('Geometry', {}),\n",
    "                    metadata={'block_id': block.get('Id', '')}\n",
    "                ))\n",
    "            \n",
    "            elif block['BlockType'] == 'KEY_VALUE_SET':\n",
    "                if block.get('EntityTypes') and 'KEY' in block['EntityTypes']:\n",
    "                    kv_content = self.extract_key_value_content(block, blocks)\n",
    "                    visual_content.append(VisualContent(\n",
    "                        content_type=\"key_value\",\n",
    "                        content=kv_content,\n",
    "                        confidence=block.get('Confidence', 0),\n",
    "                        bounding_box=block.get('Geometry', {}),\n",
    "                        metadata={'block_id': block.get('Id', '')}\n",
    "                    ))\n",
    "        \n",
    "        full_text = '\\n'.join(text_blocks)\n",
    "        return full_text, visual_content\n",
    "    \n",
    "    def extract_table_content(self, table_block: Dict, all_blocks: List[Dict]) -> str:\n",
    "        \"\"\"Convert table block to readable text format\"\"\"\n",
    "        table_text = f\"[TABLE: {table_block.get('Id', 'unknown')}]\\n\"\n",
    "        \n",
    "        # Get table relationships\n",
    "        if 'Relationships' in table_block:\n",
    "            for relationship in table_block['Relationships']:\n",
    "                if relationship['Type'] == 'CHILD':\n",
    "                    for child_id in relationship['Ids']:\n",
    "                        child_block = next((b for b in all_blocks if b['Id'] == child_id), None)\n",
    "                        if child_block and child_block['BlockType'] == 'CELL':\n",
    "                            cell_text = self.get_cell_text(child_block, all_blocks)\n",
    "                            if cell_text:\n",
    "                                table_text += f\"{cell_text} | \"\n",
    "            table_text += \"\\n\"\n",
    "        \n",
    "        return table_text\n",
    "    \n",
    "    def get_cell_text(self, cell_block: Dict, all_blocks: List[Dict]) -> str:\n",
    "        \"\"\"Extract text from table cell\"\"\"\n",
    "        cell_text = \"\"\n",
    "        if 'Relationships' in cell_block:\n",
    "            for relationship in cell_block['Relationships']:\n",
    "                if relationship['Type'] == 'CHILD':\n",
    "                    for child_id in relationship['Ids']:\n",
    "                        child_block = next((b for b in all_blocks if b['Id'] == child_id), None)\n",
    "                        if child_block and 'Text' in child_block:\n",
    "                            cell_text += child_block['Text'] + \" \"\n",
    "        return cell_text.strip()\n",
    "    \n",
    "    def extract_key_value_content(self, kv_block: Dict, all_blocks: List[Dict]) -> str:\n",
    "        \"\"\"Extract key-value pair content\"\"\"\n",
    "        return f\"[KEY_VALUE: {kv_block.get('Id', 'unknown')}]\"\n",
    "    \n",
    "    def process_document(self, file_path: str, document_type: str = \"unknown\") -> EnrichedChunk:\n",
    "        \"\"\"Process a single document and return enriched chunk\"\"\"\n",
    "        file_name = os.path.basename(file_path)\n",
    "        s3_key = f\"textract-input/{file_name}\"\n",
    "        \n",
    "        try:\n",
    "            # Upload to S3\n",
    "            if self.bucket_name:\n",
    "                self.upload_to_s3(file_path, s3_key)\n",
    "                \n",
    "                # Extract with Textract\n",
    "                textract_response = self.extract_with_textract(s3_key)\n",
    "                text_content, visual_content = self.parse_textract_response(textract_response)\n",
    "            else:\n",
    "                # Fallback: basic text extraction (for demo purposes)\n",
    "                text_content = f\"Demo text content from {file_name}\"\n",
    "                visual_content = []\n",
    "            \n",
    "            return EnrichedChunk(\n",
    "                id_=f\"{file_name}_{hash(text_content)}\",\n",
    "                text_content=text_content,\n",
    "                visual_content=visual_content,\n",
    "                document_type=document_type,\n",
    "                has_visual_elements=len(visual_content) > 0,\n",
    "                metadata={\n",
    "                    'source_file': file_name,\n",
    "                    's3_key': s3_key,\n",
    "                    'visual_element_count': len(visual_content)\n",
    "                }\n",
    "            )\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {e}\")\n",
    "            return EnrichedChunk(\n",
    "                id_=f\"{file_name}_error\",\n",
    "                text_content=f\"Error processing {file_name}\",\n",
    "                visual_content=[],\n",
    "                document_type=\"error\",\n",
    "                has_visual_elements=False,\n",
    "                metadata={'source_file': file_name, 'error': str(e)}\n",
    "            )\n",
    "\n",
    "# Initialize the processor\n",
    "# Note: Set your S3 bucket name here for full Textract functionality\n",
    "#S3_BUCKET_NAME = None  # Replace with your bucket name: \"your-textract-bucket\"\n",
    "S3_BUCKET_NAME = genaisystemevaluationmediatestbucket\n",
    "\n",
    "doc_processor = MultiModalDocumentProcessor(\n",
    "    textract_client=textract_client,\n",
    "    s3_client=s3_client,\n",
    "    bucket_name=S3_BUCKET_NAME\n",
    ")\n",
    "\n",
    "print(\"✅ Document processing pipeline initialized\")\n",
    "if S3_BUCKET_NAME:\n",
    "    print(f\"📦 Using S3 bucket: {S3_BUCKET_NAME}\")\n",
    "else:\n",
    "    print(\"⚠️  No S3 bucket configured - using demo mode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a2c4956-49ca-4cdd-9d68-e4a04ef1d93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Testing Textract on your uploaded files...\n",
      "\n",
      "🔍 Processing BusinessLicense.png...\n",
      "❌ Error processing BusinessLicense.png: Parameter validation failed:\n",
      "Invalid type for parameter Document.S3Object.Bucket, value: None, type: <class 'NoneType'>, valid types: <class 'str'>\n",
      "\n",
      "🔍 Processing DL.png...\n",
      "❌ Error processing DL.png: Parameter validation failed:\n",
      "Invalid type for parameter Document.S3Object.Bucket, value: None, type: <class 'NoneType'>, valid types: <class 'str'>\n",
      "\n",
      "🔍 Processing PayStub.png...\n",
      "❌ Error processing PayStub.png: Parameter validation failed:\n",
      "Invalid type for parameter Document.S3Object.Bucket, value: None, type: <class 'NoneType'>, valid types: <class 'str'>\n",
      "\n",
      "📄 File: BusinessLicense.png\n",
      "   ❌ Error: Parameter validation failed:\n",
      "Invalid type for parameter Document.S3Object.Bucket, value: None, type: <class 'NoneType'>, valid types: <class 'str'>\n",
      "\n",
      "📄 File: DL.png\n",
      "   ❌ Error: Parameter validation failed:\n",
      "Invalid type for parameter Document.S3Object.Bucket, value: None, type: <class 'NoneType'>, valid types: <class 'str'>\n",
      "\n",
      "📄 File: PayStub.png\n",
      "   ❌ Error: Parameter validation failed:\n",
      "Invalid type for parameter Document.S3Object.Bucket, value: None, type: <class 'NoneType'>, valid types: <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# Test processing your uploaded files\n",
    "def test_existing_files():\n",
    "    \"\"\"Test processing the files already in your S3 bucket\"\"\"\n",
    "    \n",
    "    test_files = [\n",
    "        {\"key\": \"BusinessLicense.png\", \"type\": \"business_license\"},\n",
    "        {\"key\": \"DL.png\", \"type\": \"drivers_license\"}, \n",
    "        {\"key\": \"PayStub.png\", \"type\": \"pay_stub\"}\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for file_info in test_files:\n",
    "        try:\n",
    "            print(f\"\\n🔍 Processing {file_info['key']}...\")\n",
    "            \n",
    "            # Create a mock file path since file is already in S3\n",
    "            mock_file_path = f\"/tmp/{file_info['key']}\"\n",
    "            \n",
    "            # Process using existing S3 key\n",
    "            response = textract_client.analyze_document(\n",
    "                Document={\n",
    "                    'S3Object': {\n",
    "                        'Bucket': S3_BUCKET_NAME,\n",
    "                        'Name': file_info['key']\n",
    "                    }\n",
    "                },\n",
    "                FeatureTypes=['TABLES', 'FORMS']\n",
    "            )\n",
    "            \n",
    "            # Parse the response\n",
    "            text_content, visual_content = doc_processor.parse_textract_response(response)\n",
    "            \n",
    "            result = {\n",
    "                'file': file_info['key'],\n",
    "                'type': file_info['type'],\n",
    "                'text_length': len(text_content),\n",
    "                'visual_elements': len(visual_content),\n",
    "                'text_preview': text_content[:200] + \"...\" if len(text_content) > 200 else text_content,\n",
    "                'visual_types': [vc.content_type for vc in visual_content]\n",
    "            }\n",
    "            \n",
    "            results.append(result)\n",
    "            print(f\"✅ Extracted {len(text_content)} chars of text, {len(visual_content)} visual elements\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing {file_info['key']}: {e}\")\n",
    "            results.append({\n",
    "                'file': file_info['key'],\n",
    "                'type': file_info['type'],\n",
    "                'error': str(e)\n",
    "            })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test your files\n",
    "print(\"🧪 Testing Textract on your uploaded files...\")\n",
    "test_results = test_existing_files()\n",
    "\n",
    "# Display results\n",
    "for result in test_results:\n",
    "    print(f\"\\n📄 File: {result['file']}\")\n",
    "    if 'error' in result:\n",
    "        print(f\"   ❌ Error: {result['error']}\")\n",
    "    else:\n",
    "        print(f\"   📝 Text extracted: {result['text_length']} characters\")\n",
    "        print(f\"   🖼️  Visual elements: {result['visual_elements']}\")\n",
    "        print(f\"   📋 Visual types: {result['visual_types']}\")\n",
    "        print(f\"   📖 Preview: {result['text_preview']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff35403-97a3-4dd3-bcc3-bc11d8dfa592",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
