{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52226f6b-2660-4851-818e-efecea8766c9",
   "metadata": {},
   "source": [
    "# LLM Evaluation\n",
    "\n",
    "## What Will We Do? \n",
    "* Create an eval prompt template (notebook 4a) \n",
    "* Create two different RAG prompt templates and compare results (notebook 4a) \n",
    "* Run LLM-As-A-Judge against an eval dataset and grade RAG system response (notebook 4a) \n",
    "* Run Human-Eval to ensure LLM-As-A-Judge is aligned with human preferences (notebook 4b) \n",
    "* Run Human-Eval and compare GroundTruth with RAG system response (notebook 4b)\n",
    "* **Run through evaluation with different LLMs (notebook 4c)**\n",
    "\n",
    "So let's start."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c65b599-7663-4785-bd75-0f139216fa17",
   "metadata": {},
   "source": [
    "### Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c04eab6-7444-45ae-8ce8-f731398c51d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda create -y --name llm-system-eval python=3.11.7\n",
    "# !conda init && activate llm-system-eval\n",
    "# !conda install -n llm-system-eval ipykernel --update-deps --force-reinstall -y\n",
    "# OR\n",
    "# !pyenv virtualenv 3.11.7 llm-system-eval\n",
    "# !pyenv activate llm-system-eval\n",
    "\n",
    "# %pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c38224",
   "metadata": {},
   "source": [
    "### Set Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9b58a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:lambda:us-east-1:432418664414:function:PRE-PassThrough\n",
      "arn:aws:lambda:us-east-1:432418664414:function:ACS-PassThrough\n"
     ]
    }
   ],
   "source": [
    "# set variables\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "import sagemaker\n",
    "\n",
    "import chromadb\n",
    "import boto3\n",
    "from chromadb.config import Settings\n",
    "\n",
    "# loading environment variables that are stored in local file\n",
    "local_env_filename = 'llm-system-eval.env'\n",
    "load_dotenv(find_dotenv(local_env_filename),override=True)\n",
    "os.environ['REGION'] = os.getenv('REGION')\n",
    "REGION = os.environ['REGION']\n",
    "os.environ['WORKTEAM_ARN'] = os.getenv('WORKTEAM_ARN')\n",
    "WORKTEAM_ARN = os.environ['WORKTEAM_ARN']\n",
    "os.environ['S3_BUCKET_NAME'] = os.getenv('S3_BUCKET_NAME')\n",
    "S3_BUCKET_NAME = os.environ['S3_BUCKET_NAME']\n",
    "os.environ['SAGEMAKER_ROLE_ARN'] = os.getenv('SAGEMAKER_ROLE_ARN')\n",
    "SAGEMAKER_ROLE_ARN = os.environ['SAGEMAKER_ROLE_ARN'] # OR sagemaker.get_execution_role()\n",
    "\n",
    "\n",
    "# Initialize Chroma client\n",
    "chroma_client = chromadb.Client(Settings(persist_directory=\"./chroma_db\"))\n",
    "\n",
    "# Also initialize the bedrock client so we can call some embedding models!\n",
    "session = boto3.Session(profile_name='default')\n",
    "bedrock_runtime_client = boto3.client('bedrock-runtime')\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "sagemaker_client = boto3.client('sagemaker')\n",
    "role_name = SAGEMAKER_ROLE_ARN.split(\"/\")[-1]\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "s3 = boto3.resource('s3')\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "\n",
    "# Specify ARNs for resources needed to run an text classification job.\n",
    "ac_arn_map = {\n",
    "    \"us-west-2\": \"081040173940\",\n",
    "    \"us-east-1\": \"432418664414\",\n",
    "    \"us-east-2\": \"266458841044\",\n",
    "    \"eu-west-1\": \"568282634449\"\n",
    "}\n",
    "# PreHumanTaskLambdaArn for text classification(single)\n",
    "prehuman_arn = \"arn:aws:lambda:{}:{}:function:PRE-PassThrough\".format(\n",
    "    REGION, ac_arn_map[REGION]\n",
    ")\n",
    "\n",
    "# AnnotationConsolidationConfig for text classification(single)\n",
    "acs_arn = \"arn:aws:lambda:{}:{}:function:ACS-PassThrough\".format(REGION, ac_arn_map[REGION])\n",
    "\n",
    "print(prehuman_arn)\n",
    "print(acs_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0c0ac01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER validation helper classes\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import boto3\n",
    "from botocore.config import Config\n",
    "import io\n",
    "from io import StringIO\n",
    "import time\n",
    "import re\n",
    "import typing as t\n",
    "from queue import Queue\n",
    "from threading import Thread\n",
    "from numpy.linalg import norm\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "class Util():\n",
    "    def __init__(self,\n",
    "        debug: bool = False\n",
    "\n",
    "    ):\n",
    "\n",
    "        self.debug = debug\n",
    "        self.wrapper = BedrockLLMWrapper(model_id='anthropic.claude-3-sonnet-20240229-v1:0', temperature=0,max_token_count=1000)\n",
    "\n",
    "    REASONING_PATTERN = r'<thinking>(.*?)</thinking>'\n",
    "    SCORE_PATTERN = r'<score>(.*?)</score>'\n",
    "    ANSWER_PATTERN = r'<question_answer>(.*?)</question_answer>'\n",
    "\n",
    "    # Strip out the portion of the response with regex.\n",
    "    def extract_with_regex(self, response, regex):\n",
    "        matches = re.search(regex, response, re.DOTALL)\n",
    "        # Extract the matched content, if any\n",
    "        return matches.group(1).strip() if matches else None\n",
    "\n",
    "    def format_results(self, grade: str, chat_conversation: list[dict]) -> dict:\n",
    "        reasoning: str = self.extract_with_regex(grade, self.REASONING_PATTERN)\n",
    "        score: str =  self.extract_with_regex(grade, self.SCORE_PATTERN)\n",
    "        \n",
    "        return {\n",
    "            'chat_conversation': chat_conversation,\n",
    "            'reasoning': reasoning,\n",
    "            'score': score\n",
    "        }\n",
    "\n",
    "    def compare_results(self, answer_results1, answer_results2):\n",
    "        \n",
    "\n",
    "        # # Function to convert 'score' column\n",
    "        def convert_score(df):\n",
    "            # df['score'] = df['score'].map({'correct': 1, 'incorrect': 0})\n",
    "            df['score'] = pd.to_numeric(df['score'], errors='coerce').fillna(0).astype(int)\n",
    "            return df\n",
    "\n",
    "        # Apply the conversion to both dataframes\n",
    "        answer_results1 = convert_score(answer_results1)\n",
    "        answer_results2 = convert_score(answer_results2)\n",
    "\n",
    "        # Calculate the average values for each metric\n",
    "        metrics = ['score', 'faithfulness' ,'answer_relevancy', 'latency', 'cost']\n",
    "        avg_results1 = [answer_results1[metric].mean() for metric in metrics]\n",
    "        avg_results2 = [answer_results2[metric].mean() for metric in metrics]\n",
    "\n",
    "        # Calculate percentage change, handling divide-by-zero and infinite cases\n",
    "        def safe_percent_change(a, b):\n",
    "            if pd.isna(a) or pd.isna(b):\n",
    "                return 0\n",
    "            if a == 0 and b == 0:\n",
    "                return 0\n",
    "            elif a == 0:\n",
    "                return 100  # Arbitrarily set to 100% increase if original value was 0\n",
    "            else:\n",
    "                change = (b - a) / a * 100\n",
    "                return change if np.isfinite(change) else 0\n",
    "\n",
    "        percent_change = [safe_percent_change(a, b) for a, b in zip(avg_results1, avg_results2)]\n",
    "\n",
    "        # Set up the bar chart\n",
    "        x = np.arange(len(metrics))\n",
    "        width = 0.5\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "        # Create the bars\n",
    "        bars = ax.bar(x, percent_change, width)\n",
    "\n",
    "        # Customize the chart\n",
    "        ax.set_ylabel('Percentage Change (%)')\n",
    "        ax.set_title('Percentage Change in Metrics (Results 2 vs Results 1)')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(metrics)\n",
    "\n",
    "        # Add a horizontal line at y=0\n",
    "        ax.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "\n",
    "        # Add value labels on top of each bar\n",
    "        def autolabel(rects):\n",
    "            for rect in rects:\n",
    "                height = rect.get_height()\n",
    "                ax.annotate(f'{height:.2f}%',\n",
    "                            xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                            xytext=(0, 3 if height >= 0 else -3),  # 3 points vertical offset\n",
    "                            textcoords=\"offset points\",\n",
    "                            ha='center', va='bottom' if height >= 0 else 'top')\n",
    "\n",
    "        autolabel(bars)\n",
    "\n",
    "        # Color the bars based on positive (green) or negative (red) change\n",
    "        # For latency & cost, reverse the color logic\n",
    "        for bar, change, metric in zip(bars, percent_change, metrics):\n",
    "            if metric == 'latency' or metric == 'cost':\n",
    "                bar.set_color('green' if change <= 0 else 'red')\n",
    "            else:\n",
    "                bar.set_color('green' if change >= 0 else 'red')\n",
    "            \n",
    "\n",
    "        # Adjust layout and display the chart\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def calculate_faithfulness(self, answer, context, similarity_threshold=0.3):\n",
    "        # Tokenize the answer into sentences (potential claims)\n",
    "        claims = sent_tokenize(answer)\n",
    "        \n",
    "        # Get stop words as a list\n",
    "        stop_words = list(stopwords.words('english'))\n",
    "        \n",
    "        # Initialize TfidfVectorizer\n",
    "        vectorizer = TfidfVectorizer(stop_words=stop_words)\n",
    "        \n",
    "        # Fit the vectorizer on the context and claims\n",
    "        all_text = [context] + claims\n",
    "        tfidf_matrix = vectorizer.fit_transform(all_text)\n",
    "        \n",
    "        # Get the context vector (first row of the matrix)\n",
    "        context_vector = tfidf_matrix[0]\n",
    "        \n",
    "        # Initialize counters\n",
    "        total_claims = len(claims)\n",
    "        # print(f'total_claims: {total_claims}')\n",
    "        supported_claims = 0\n",
    "        \n",
    "        # Calculate similarity between each claim and the context\n",
    "        for i, claim in enumerate(claims, start=1):\n",
    "            claim_vector = tfidf_matrix[i]\n",
    "            similarity = cosine_similarity(context_vector, claim_vector)[0][0]\n",
    "            # print(f'similarity: {similarity}')\n",
    "            # If similarity is above a threshold, consider it supported\n",
    "            if similarity > similarity_threshold:  # You can adjust this threshold\n",
    "                supported_claims += 1\n",
    "        \n",
    "        # Calculate faithfulness score\n",
    "        faithfulness_score = supported_claims / total_claims if total_claims > 0 else 0\n",
    "        rounded_score = round(faithfulness_score, 3)\n",
    "        return rounded_score\n",
    "\n",
    "    def calculate_answer_relevance(self, actual_question, generated_answer, n=3):\n",
    "\n",
    "        # Step 1: Generate 'n' variants of the question using Amazon Bedrock\n",
    "        prompt = f\"\"\"Human: \n",
    "        Given the following answer, generate {n} possible questions that could have led to this answer:\n",
    "\n",
    "        Answer: {generated_answer}\n",
    "\n",
    "        Generate {n} different questions.\n",
    "        Assistant:\n",
    "        \"\"\"\n",
    "        response = self.wrapper.generate(prompt)\n",
    "        \n",
    "        generated_questions = response[0]\n",
    "        # mean_cosine_similarity = self.cosine_similarity(actual_question, generated_questions)\n",
    "\n",
    "        # Step 2: Vectorize the actual question and generated questions\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        all_questions = [actual_question] + generated_questions.split('\\n')\n",
    "        tfidf_matrix = vectorizer.fit_transform(all_questions)\n",
    "\n",
    "        # Step 3: Calculate cosine similarity between actual question and each generated question\n",
    "        actual_question_vector = tfidf_matrix[0]\n",
    "        generated_questions_vectors = tfidf_matrix[1:]\n",
    "        similarities = cosine_similarity(actual_question_vector, generated_questions_vectors)\n",
    "\n",
    "        # Step 4: Calculate the mean cosine similarity\n",
    "        mean_cosine_similarity = similarities.mean()\n",
    "        rounded_score = round(mean_cosine_similarity, 3)\n",
    "        return rounded_score\n",
    "            \n",
    "    \n",
    "\n",
    "    def calculate_cost(self, usage, model_id):\n",
    "        '''\n",
    "        Takes the usage tokens returned by Bedrock in input and output, and coverts to cost in dollars.\n",
    "        '''\n",
    "        \n",
    "        input_token_haiku = 0.25/1000000\n",
    "        output_token_haiku = 1.25/1000000\n",
    "        input_token_sonnet = 3.00/1000000\n",
    "        output_token_sonnet = 15.00/1000000\n",
    "        input_token_opus = 15.00/1000000\n",
    "        output_token_opus = 75.00/1000000\n",
    "        \n",
    "        input_token_titan_embeddingv1 = 0.1/1000000\n",
    "        input_token_titan_embeddingv2 = 0.02/1000000\n",
    "        input_token_titan_embeddingmultimodal = 0.8/1000000\n",
    "        input_token_titan_premier = 0.5/1000000\n",
    "        output_token_titan_premier = 1.5/1000000\n",
    "        input_token_titan_lite = 0.15/1000000\n",
    "        output_token_titan_lite = 0.2/1000000\n",
    "        input_token_titan_express = 0.2/1000000\n",
    "        output_token_titan_express = 0.6/1000000\n",
    "       \n",
    "        input_token_cohere_command = 0.15/1000000\n",
    "        output_token_cohere_command = 2/1000000\n",
    "        input_token_cohere_commandlight = 0.3/1000000\n",
    "        output_token_cohere_commandlight = 0.6/1000000\n",
    "        input_token_cohere_commandrplus = 3/1000000\n",
    "        output_token_cohere_commandrplus = 15/1000000\n",
    "        input_token_cohere_commandr = 5/1000000\n",
    "        output_token_cohere_commandr = 1.5/1000000\n",
    "        input_token_cohere_embedenglish = 0.1/1000000\n",
    "        input_token_cohere_embedmultilang = 0.1/1000000\n",
    "\n",
    "        input_token_llama3_8b = 0.4/1000000\n",
    "        output_token_llama3_8b = 0.6/1000000\n",
    "        input_token_llama3_70b = 2.6/1000000\n",
    "        output_token_llama3_70b = 3.5/1000000\n",
    "\n",
    "        input_token_mistral_8b = 0.15/1000000\n",
    "        output_token_mistral_8b = 0.2/1000000\n",
    "        input_token_mistral_large = 4/1000000\n",
    "        output_token_mistral_large = 12/1000000\n",
    "\n",
    "        cost = 0\n",
    "\n",
    "        if 'haiku' in model_id:\n",
    "            cost+= usage['inputTokens']*input_token_haiku\n",
    "            cost+= usage['outputTokens']*output_token_haiku\n",
    "        if 'sonnet' in model_id:\n",
    "            cost+= usage['inputTokens']*input_token_sonnet\n",
    "            cost+= usage['outputTokens']*output_token_sonnet\n",
    "        if 'opus' in model_id:\n",
    "            cost+= usage['inputTokens']*input_token_opus\n",
    "            cost+= usage['outputTokens']*output_token_opus\n",
    "        if 'amazon.titan-embed-text-v1' in model_id:\n",
    "            cost+= usage['inputTokens']*input_token_titan_embeddingv1\n",
    "        if 'amazon.titan-embed-text-v2' in model_id:\n",
    "            cost+= usage['inputTokens']*input_token_titan_embeddingv2\n",
    "        if 'cohere.embed-multilingual' in model_id:\n",
    "            cost+= usage['inputTokens']*input_token_cohere_embedmultilang\n",
    "        if 'cohere.embed-english' in model_id:\n",
    "            cost+= usage['inputTokens']*input_token_cohere_embedenglish \n",
    "        if 'meta.llama3-8b-instruct' in model_id:\n",
    "            cost+= usage['inputTokens']*input_token_llama3_8b\n",
    "            cost+= usage['outputTokens']*output_token_llama3_8b\n",
    "        if 'meta.llama3-70b-instruct' in model_id:\n",
    "            cost+= usage['inputTokens']*input_token_llama3_70b\n",
    "            cost+= usage['outputTokens']*output_token_llama3_70b\n",
    "        if 'cohere.command-text' in model_id:\n",
    "            cost+= usage['inputTokens']*input_token_cohere_command\n",
    "            cost+= usage['outputTokens']*output_token_cohere_command\n",
    "        if 'cohere.command-light-text' in model_id:\n",
    "            cost+= usage['inputTokens']*input_token_cohere_commandlight\n",
    "            cost+= usage['outputTokens']*output_token_cohere_commandlight\n",
    "        if 'cohere.command-r-plus' in model_id:\n",
    "            cost+= usage['inputTokens']*input_token_cohere_commandrplus\n",
    "            cost+= usage['outputTokens']*output_token_cohere_commandrplus\n",
    "        if 'cohere.command-r' in model_id:\n",
    "            cost+= usage['inputTokens']*input_token_cohere_commandr\n",
    "            cost+= usage['outputTokens']*output_token_cohere_commandr\n",
    "        if 'amazon.titan-text-express' in model_id:\n",
    "            cost+= usage['inputTokens']*input_token_titan_express\n",
    "            cost+= usage['outputTokens']*output_token_titan_express\n",
    "        if 'amazon.titan-text-lite' in model_id:\n",
    "            cost+= usage['inputTokens']*input_token_titan_lite\n",
    "            cost+= usage['outputTokens']*output_token_titan_lite\n",
    "        if 'amazon.titan-text-premier' in model_id:\n",
    "            cost+= usage['inputTokens']*input_token_titan_premier\n",
    "            cost+= usage['outputTokens']*output_token_titan_premier\n",
    "        if 'mistral.mixtral-8x7b-instruct-v0:1' in model_id:\n",
    "            cost+= usage['inputTokens']*input_token_mistral_8b\n",
    "            cost+= usage['outputTokens']*output_token_mistral_8b\n",
    "\n",
    "        return cost\n",
    "\n",
    "class BedrockLLMWrapper():\n",
    "    def __init__(self,\n",
    "        model_id: str = 'anthropic.claude-3-haiku-20240307-v1:0',\n",
    "        top_k: int = 5,\n",
    "        top_p: int = 0.7,\n",
    "        temperature: float = 0.0,\n",
    "        max_token_count: int = 4000,\n",
    "        max_attempts: int = 3,\n",
    "        debug: bool = False,\n",
    "        region: str ='us-east-1'\n",
    "\n",
    "    ):\n",
    "\n",
    "        self.model_id = model_id\n",
    "        self.top_k = top_k\n",
    "        self.top_p = top_p\n",
    "        self.temperature = temperature\n",
    "        self.max_token_count = max_token_count\n",
    "        self.max_attempts = max_attempts\n",
    "        self.region = region\n",
    "        self.debug = debug\n",
    "        config = Config(\n",
    "            retries = {\n",
    "                'max_attempts': 10,\n",
    "                'mode': 'standard'\n",
    "            }\n",
    "        )\n",
    "\n",
    "        self.bedrock_runtime = boto3.client(service_name=\"bedrock-runtime\", config=config, region_name=self.region)\n",
    "    \n",
    "    def get_embedding(self, body, modelId, accept, contentType):\n",
    "        response = self.bedrock_runtime.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "        response_body = json.loads(response.get('body').read())\n",
    "        embedding = response_body.get('embedding')\n",
    "        return embedding\n",
    "    \n",
    "    def generate(self,prompt):\n",
    "        if self.debug: \n",
    "            print('entered BedrockLLMWrapper generate')\n",
    "        attempt = 1\n",
    "\n",
    "        message = {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [{\"text\": prompt}]\n",
    "        }\n",
    "        messages = []\n",
    "        messages.append(message)\n",
    "        \n",
    "        # model specific inference parameters to use.\n",
    "        if \"anthropic\" in self.model_id.lower():\n",
    "            # system_prompts = [{\"text\": \"You are a helpful AI Assistant.\"}]\n",
    "            system_prompts = []\n",
    "            # Base inference parameters to use.\n",
    "            inference_config = {\n",
    "                                \"temperature\": self.temperature, \n",
    "                                \"maxTokens\": self.max_token_count,\n",
    "                                \"stopSequences\": [\"\\n\\nHuman:\"],\n",
    "                                \"topP\": self.top_p,\n",
    "                            }\n",
    "            additional_model_fields = {\"top_k\": self.top_k}\n",
    "        else:\n",
    "            system_prompts = []\n",
    "            # Base inference parameters to use.\n",
    "            inference_config = {\n",
    "                                \"temperature\": self.temperature, \n",
    "                                \"maxTokens\": self.max_token_count,\n",
    "                            }\n",
    "            additional_model_fields = {\"top_k\": self.top_k}\n",
    "\n",
    "        if self.debug: \n",
    "            print(\"Sending:\\nSystem:\\n\",str(system_prompts),\"\\nMessages:\\n\",str(messages))\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "\n",
    "                # Send the message.\n",
    "                response = self.bedrock_runtime.converse(\n",
    "                    modelId=self.model_id,\n",
    "                    messages=messages,\n",
    "                    system=system_prompts,\n",
    "                    inferenceConfig=inference_config,\n",
    "                    additionalModelRequestFields=additional_model_fields\n",
    "                )\n",
    "\n",
    "                # Log token usage.\n",
    "                text = response['output'].get('message').get('content')[0].get('text')\n",
    "                usage = response['usage']\n",
    "                latency = response['metrics'].get('latencyMs')\n",
    "\n",
    "                if self.debug: \n",
    "                    print(f'text: {text} ; and token usage: {usage} ; and query_time: {latency}')    \n",
    "                \n",
    "                break\n",
    "               \n",
    "            except Exception as e:\n",
    "                print(\"Error with calling Bedrock: \"+str(e))\n",
    "                attempt+=1\n",
    "                if attempt>self.max_attempts:\n",
    "                    print(\"Max attempts reached!\")\n",
    "                    result_text = str(e)\n",
    "                    break\n",
    "                else:#retry in 10 seconds\n",
    "                    print(\"retry\")\n",
    "                    time.sleep(10)\n",
    "\n",
    "        # return result_text\n",
    "        return [text,usage,latency]\n",
    "\n",
    "    # Threaded function for queue processing.\n",
    "    def thread_request(self, q, results):\n",
    "        while True:\n",
    "            try:\n",
    "                index, prompt = q.get(block=False)\n",
    "                data = self.generate(prompt)\n",
    "                results[index] = data\n",
    "            except Queue.Empty:\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f'Error with prompt: {str(e)}')\n",
    "                results[index] = str(e)\n",
    "            finally:\n",
    "                q.task_done()\n",
    "\n",
    "    def generate_threaded(self, prompts, max_workers=15):\n",
    "        results = [None] * len(prompts)\n",
    "        \n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            future_to_index = {executor.submit(self.generate, prompt): i for i, prompt in enumerate(prompts)}\n",
    "            for future in as_completed(future_to_index):\n",
    "                index = future_to_index[future]\n",
    "                try:\n",
    "                    results[index] = future.result()\n",
    "                except Exception as exc:\n",
    "                    print(f'Generated an exception: {exc}')\n",
    "                    results[index] = str(exc)\n",
    "        \n",
    "        return results\n",
    "\n",
    "class AnswerTaskRunner:\n",
    "    def __init__(self, eval_df: pd.DataFrame, \n",
    "                 model_id:str = 'anthropic.claude-3-sonnet-20240229-v1:0',\n",
    "                 eval_model_id:str = 'anthropic.claude-3-sonnet-20240229-v1:0',\n",
    "                 temperature: float = 0.0,\n",
    "                 max_token_count: int = 2000,\n",
    "                 max_attempts: int = 3, \n",
    "                 prompt_template: str = '',\n",
    "                 prompt_eval_template: str = ''):\n",
    "        self.eval_df = eval_df\n",
    "        self.model_id = model_id\n",
    "        self.eval_model_id = eval_model_id\n",
    "        self.temperature = temperature\n",
    "        self.max_token_count = max_token_count\n",
    "        self.max_attempts = max_attempts\n",
    "        self.prompt_template = prompt_template\n",
    "        self.prompt_eval_template = prompt_eval_template\n",
    "        self.wrapper = BedrockLLMWrapper(model_id=self.model_id, \n",
    "                                         max_token_count=self.max_token_count,\n",
    "                                         temperature=self.temperature\n",
    "                                         )\n",
    "        self.eval_wrapper = BedrockLLMWrapper(model_id=self.eval_model_id, \n",
    "                                         max_token_count=self.max_token_count,\n",
    "                                         temperature=self.temperature\n",
    "                                         )\n",
    "\n",
    "    def get_prompt(self, question, context_list):\n",
    "        context = context_list\n",
    "        prompt = self.prompt_template.format(question=question, context=context)\n",
    "        return prompt\n",
    "\n",
    "    def build_grader_prompt(self, original_query: str, llm_system_response: str, ground_truth_answer:str, context_list, answer_relevancy:str):\n",
    "        context = context_list\n",
    "\n",
    "        prompt = self.prompt_eval_template.format(\n",
    "                        original_query= original_query,\n",
    "                        llm_system_response= llm_system_response,\n",
    "                        ground_truth_answer=ground_truth_answer,\n",
    "                        context=context,\n",
    "                        answer_relevancy = answer_relevancy,\n",
    "                        \n",
    "                    ) \n",
    "        return prompt\n",
    "\n",
    "    def run(self) -> pd.DataFrame:\n",
    "        df = pd.DataFrame(self.eval_df)\n",
    "        util = Util()\n",
    "        \n",
    "        # Prepare prompts for answer generation\n",
    "        answer_prompts = [self.get_prompt(row['query_text'], row['context']) for _, row in df.iterrows()]\n",
    "        \n",
    "        # Generate answers in parallel\n",
    "        answer_responses = self.wrapper.generate_threaded(answer_prompts)\n",
    "        \n",
    "        eval_prompts = []\n",
    "        for (_, row), response in zip(df.iterrows(), answer_responses):\n",
    "            query = row['query_text']\n",
    "            groundtruth_answer = row['question_answer']\n",
    "            retrieved_chunks = row['context']\n",
    "            \n",
    "            generated_answer = util.extract_with_regex(str(response[0]), util.ANSWER_PATTERN)\n",
    "            \n",
    "            answer_relevancy = util.calculate_answer_relevance(query, generated_answer) if generated_answer else 0\n",
    "            \n",
    "            eval_prompts.append(self.build_grader_prompt(query, generated_answer, groundtruth_answer, retrieved_chunks, answer_relevancy))\n",
    "        \n",
    "        # Generate evaluations in parallel\n",
    "        eval_responses = self.eval_wrapper.generate_threaded(eval_prompts)\n",
    "        \n",
    "        results = []\n",
    "        for (_, row), answer_response, eval_response in zip(df.iterrows(), answer_responses, eval_responses):\n",
    "            query = row['query_text']\n",
    "            groundtruth_answer = row['question_answer']\n",
    "            retrieved_chunks = row['context']\n",
    "            \n",
    "            generated_answer = util.extract_with_regex(str(answer_response[0]), util.ANSWER_PATTERN)\n",
    "            \n",
    "            reasoning = util.extract_with_regex(str(eval_response[0]), util.REASONING_PATTERN)\n",
    "            score = util.extract_with_regex(str(eval_response[0]), util.SCORE_PATTERN)\n",
    "            \n",
    "            answer_relevancy = util.calculate_answer_relevance(query, generated_answer) if generated_answer else 0\n",
    "            faithfulness = util.calculate_faithfulness(generated_answer, retrieved_chunks) if generated_answer else 0\n",
    "            \n",
    "            cost = util.calculate_cost(answer_response[1], self.model_id)\n",
    "            \n",
    "            result = {\n",
    "                'query_text': query,\n",
    "                'groundtruth_answer': groundtruth_answer,\n",
    "                'retrieved_chunks': json.dumps(retrieved_chunks),\n",
    "                'generated_answer': generated_answer,\n",
    "                'usage': json.dumps(answer_response[1]),\n",
    "                'latency': answer_response[2],\n",
    "                'reasoning': str(reasoning),\n",
    "                'score': score,\n",
    "                'faithfulness': faithfulness,\n",
    "                'answer_relevancy': answer_relevancy,\n",
    "                'cost': cost,\n",
    "            }\n",
    "            results.append(result)\n",
    "        \n",
    "        return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a395ade",
   "metadata": {},
   "source": [
    "### LLM-as-a-Judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b915cdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt Evaluation Template\n",
    "## this template could be improved by adding eval examples.\n",
    "\n",
    "prompt_eval_template = \"\"\"You are an expert judge evaluating the Retrieval Augmented Generation applications.\n",
    "                   Your task is to evaluate a given answer based on a context and question using the criteria provided below.\n",
    " \n",
    "                    Evaluation Criteria (Additive Score, 0-3):\n",
    "                    1. Context: Award 1 point if the answer uses only information provided in the context, without introducing external or fabricated details.\n",
    "                    2. Completeness: Add 1 point if the answer addresses all key elements of the question based on the available context, without omissions.\n",
    "                    3. Conciseness: Add a final point if the answer uses the fewest words possible to address the question and avoids redundancy.\n",
    "                    \n",
    "                    Evaluation Steps:\n",
    "                    1. Read provided context, question and answer carefully.\n",
    "                    2. Go through each evaluation criterion one by one and assess whether the answer meets the criteria.\n",
    "                    3. Compose your reasoning for each critera, explaining why you did or did not award a point. You can only award full points. \n",
    "                    4. Calculate the total score by summing the points awarded.\n",
    "                    5. Think through the evaluation criteria inside <thinking></thinking> tags. \n",
    "                    Then, output the total score inside <score></score> tags.\n",
    "                    Review your formatted response. It needs to be valid XML.\n",
    "\n",
    "                    Now, please evaluate the following:\n",
    "\n",
    "                    Question:\n",
    "                    <original_query>\n",
    "                    {original_query}\n",
    "                    </original_query>\n",
    "\n",
    "                    Generated answer:\n",
    "                    <llm_system_response>\n",
    "                    {llm_system_response}\n",
    "                    </llm_system_response>\n",
    "\n",
    "                    Ground truth answer:\n",
    "                    <ground_truth_answer>\n",
    "                    {ground_truth_answer}\n",
    "                    </ground_truth_answer>\n",
    "\n",
    "                    Context:\n",
    "                    <context>\n",
    "                    {context}\n",
    "                    </context>\n",
    "\n",
    "                    Here is the answer_relevancy score based of the original question and generated questions based of the generated answer.\n",
    "                    <answer_relevancy>\n",
    "                    {answer_relevancy}\n",
    "                    </answer_relevancy>\n",
    "                    The answer_relevancy score range between 0 and 1 where higher scores indicate better relevancy.\n",
    "                \n",
    "                    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c63ff90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM eval 1\n",
    "\n",
    "EVAL_PATH = '../data/eval-datasets/4_answer_validation_opensearch.jsonl'\n",
    "answer_eval_df = pd.read_json(EVAL_PATH,lines=True)\n",
    "\n",
    "MODEL_ID = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "EVAL_MODEL_ID = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "\n",
    "prompt_template_claude_1 = \"\"\"\n",
    "        Human: \n",
    "        You are a helpful, respectful, and honest research assistant, dedicated to providing valuable and accurate information.\n",
    "        You will be provided with a report extract between <report></report> XML tags, please read it and analyse the content.\n",
    "        Please answer the following question: \n",
    "        {question} \n",
    "        \n",
    "        The answer must only be based on the information from the context below.\n",
    "\n",
    "        If a particular bit of information is not present, return \"There is not enough information available to answer this question\" inside the XML tags.\n",
    "        Each returned answer should be concise, remove extra information if possible.\n",
    "        The context will be given between <context></context> XML tags.\n",
    "\n",
    "        <context>\n",
    "        {context}\n",
    "        </context>\n",
    "\n",
    "        Return the answer inside <question_answer></question_answer> XML tags.\n",
    "        Assistant:\"\"\"\n",
    "\n",
    "llm_results1: pd.DataFrame = AnswerTaskRunner(answer_eval_df,model_id=MODEL_ID,eval_model_id=EVAL_MODEL_ID, prompt_template=prompt_template_claude_1, prompt_eval_template=prompt_eval_template).run()\n",
    "llm_results1.to_json('../data/eval-datasets/4_llm_validation_opensearch_graded1.jsonl', orient='records', lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c2f5f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM eval 2\n",
    "MODEL_ID = \"anthropic.claude-3-haiku-20240307-v1:0\"\n",
    "EVAL_MODEL_ID = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "\n",
    "llm_results2: pd.DataFrame = AnswerTaskRunner(answer_eval_df,model_id=MODEL_ID, eval_model_id=EVAL_MODEL_ID, prompt_template=prompt_template_claude_1, prompt_eval_template=prompt_eval_template).run()\n",
    "llm_results2.to_json('../data/eval-datasets/4_llm_validation_opensearch_graded2.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734304de",
   "metadata": {},
   "source": [
    "### Review results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31aa863a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "util = Util()\n",
    "util.compare_results(llm_results1, llm_results2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1d4a5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage correct for answer_results1: 75.00%\n",
      "Percentage correct for answer_results2: 45.83%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe table table-striped\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>query_text</th>\n",
       "      <th>groundtruth_answer</th>\n",
       "      <th>generated_answer</th>\n",
       "      <th>usage</th>\n",
       "      <th>latency</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>score</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Can you show me some different examples of using different quantization methods for vectors?</td>\n",
       "      <td>&lt;question_answer&gt;\\nThere is not enough information available to answer this question. The context provides details on different quantization methods for vectors supported by the OpenSearch k-NN plugin, such as Lucene byte vectors, Lucene scalar quantization, Faiss 16-bit scalar quantization, and Faiss product quantization. However, it does not provide specific examples of using these methods.\\n&lt;/question_answer&gt;</td>\n",
       "      <td>There is not enough information available to answer this question. The given context provides details on different quantization methods for vectors supported by the OpenSearch k-NN plugin, such as Lucene byte vectors, Lucene scalar quantization, Faiss 16-bit scalar quantization, and Faiss product quantization. However, it does not provide specific examples of using these methods.</td>\n",
       "      <td>{\"inputTokens\": 4639, \"outputTokens\": 96, \"totalTokens\": 4735}</td>\n",
       "      <td>4186</td>\n",
       "      <td>Context:\\n1. The context provides details on different quantization methods for vectors supported by the OpenSearch k-NN plugin, such as Lucene byte vectors, Lucene scalar quantization, Faiss 16-bit scalar quantization, and Faiss product quantization. However, it does not provide specific examples of using these methods.\\n\\nCompleteness:\\n1. The generated answer correctly states that the context does not provide enough information to answer the question about showing examples of using different quantization methods for vectors. It addresses the key elements of the question based on the available context.\\nScore: 1\\n\\nConciseness:\\n1. The generated answer is concise and uses the fewest words possible to address the lack of information in the context to answer the question.\\nScore: 1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.015357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>What specific Java permission is required to register and unregister MBeans when installing the anomaly detection plugin, and what exact object does this permission apply to?</td>\n",
       "      <td>&lt;question_answer&gt;\\nThe specific Java permission required to register and unregister MBeans when installing the anomaly detection plugin is:\\n\\njavax.management.MBeanPermission org.apache.commons.pool2.impl.GenericObjectPool#-[org.apache.commons.pool2:name=pool,type=GenericObjectPool] registerMBean\\njavax.management.MBeanPermission org.apache.commons.pool2.impl.GenericObjectPool#-[org.apache.commons.pool2:name=pool,type=GenericObjectPool] unregisterMBean\\n\\nThis permission applies to the org.apache.commons.pool2.impl.GenericObjectPool object.\\n&lt;/question_answer&gt;</td>\n",
       "      <td>The specific Java permission required to register and unregister MBeans when installing the anomaly detection plugin is:\\n\\njavax.management.MBeanPermission org.apache.commons.pool2.impl.GenericObjectPool#-[org.apache.commons.pool2:name=pool,type=GenericObjectPool] registerMBean\\njavax.management.MBeanPermission org.apache.commons.pool2.impl.GenericObjectPool#-[org.apache.commons.pool2:name=pool,type=GenericObjectPool] unregisterMBean\\n\\nThis permission applies to the org.apache.commons.pool2.impl.GenericObjectPool object.</td>\n",
       "      <td>{\"inputTokens\": 5220, \"outputTokens\": 165, \"totalTokens\": 5385}</td>\n",
       "      <td>5596</td>\n",
       "      <td>Context:\\n1. The context does not provide any information about the specific Java permission required to register and unregister MBeans when installing the anomaly detection plugin. The answer appears to be using information not present in the given context, so I will not award a point for this criterion.\\n\\nCompleteness:\\n2. The answer directly addresses the question by providing the specific Java permissions required to register and unregister MBeans for the anomaly detection plugin, as well as the object to which these permissions apply. It covers all key elements of the question, so I will award 1 point for completeness.\\n\\nConciseness:\\n3. The answer is concise and uses the fewest words necessary to address the question without redundancy, so I will award 1 point for conciseness.</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.018135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>How can I group my data by a nested field but still calculate metrics on a parent-level field in the same query?</td>\n",
       "      <td>&lt;question_answer&gt;\\nThe context does not provide enough information to answer how to group data by a nested field while calculating metrics on a parent-level field in the same query. The context explains the reverse_nested aggregation, which allows aggregating values from nested documents to their parent, but does not specifically address grouping by nested fields and calculating parent-level metrics in the same query.\\n&lt;/question_answer&gt;</td>\n",
       "      <td>The context does not provide enough information to answer how to group data by a nested field while calculating metrics on a parent-level field in the same query. The context explains the reverse_nested aggregation, which allows aggregating values from nested documents to their parent, but does not specifically address grouping by nested fields and calculating parent-level metrics in the same query.</td>\n",
       "      <td>{\"inputTokens\": 894, \"outputTokens\": 89, \"totalTokens\": 983}</td>\n",
       "      <td>2072</td>\n",
       "      <td>Context:\\n1. The context explains the reverse_nested aggregation, which allows aggregating values from nested documents to their parent. However, it does not provide information on how to group data by a nested field while calculating metrics on a parent-level field in the same query. Therefore, I will not award a point for this criterion.\\n\\nCompleteness:\\n2. The generated answer correctly states that the context does not provide enough information to answer the original question about grouping by nested fields and calculating parent-level metrics in the same query. Since the answer addresses all key elements of the question based on the available context, I will award 1 point for completeness.\\n\\nConciseness:\\n3. The generated answer is concise and uses the fewest words possible to address the question without redundancy. Therefore, I will award 1 point for conciseness.</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.004017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe table table-striped\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>query_text</th>\n",
       "      <th>groundtruth_answer</th>\n",
       "      <th>generated_answer</th>\n",
       "      <th>usage</th>\n",
       "      <th>latency</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>score</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>What is the difference between vector search and full text search?</td>\n",
       "      <td>&lt;question_answer&gt;\\nThe main difference between vector search and full text search is:\\n\\nVector search is used to find similar or semantically related documents to a given query, based on vector representations of the text. It calculates the similarity between the query vector and document vectors, and returns the most similar documents.\\n\\nFull text search is used to find documents that contain the exact words or terms in the query. It analyzes the query text and matches it against an inverted index of terms in the documents, returning documents that contain those terms.\\n\\nThere is not enough information available in the given context to explain the difference between vector search and full text search.\\n&lt;/question_answer&gt;</td>\n",
       "      <td>The main difference between vector search and full text search is:\\n\\nVector search is used to find similar or semantically related documents to a given query, based on vector representations of the text. It calculates the similarity between the query vector and document vectors, and returns the most similar documents.\\n\\nFull text search is used to find documents that contain the exact words or terms in the query. It analyzes the query text and matches it against an inverted index of terms in the documents, returning documents that contain those terms.\\n\\nThere is not enough information available in the given context to explain the difference between vector search and full text search.</td>\n",
       "      <td>{\"inputTokens\": 2587, \"outputTokens\": 143, \"totalTokens\": 2730}</td>\n",
       "      <td>6874</td>\n",
       "      <td>Context:\\n1. The context provides a detailed explanation of the difference between vector search and full text search, covering aspects like how they work, what they are used for, and how they handle relevance scoring. Since the generated answer accurately reflects the information in the context without introducing any external details, I will award 1 point for this criterion.\\n\\nCompleteness:\\n2. The generated answer comprehensively addresses the key elements of the question by explaining the main difference between vector search and full text search, including how they handle similarity/relevance scoring and exact term matching. It covers all the important points mentioned in the context. Therefore, I will award 1 point for completeness.\\n\\nConciseness:\\n3. The generated answer is concise and uses the fewest words necessary to address the question without redundancy. It directly states the main difference and provides supporting details in a clear and succinct manner. I will award 1 point for conciseness.</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.009906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>I have a custom model, can I run it in Opensearch?</td>\n",
       "      <td>&lt;question_answer&gt;\\nYes, you can run your custom model in OpenSearch. The documentation provides instructions on how to register and deploy a custom model in OpenSearch. You need to provide the model file URL, model configuration details like model type and embedding dimension, and other metadata to register the model. Once registered, you can deploy the model and use it for inference tasks like text embedding or neural search.\\n&lt;/question_answer&gt;</td>\n",
       "      <td>Yes, you can run your custom model in OpenSearch. The documentation provides instructions on how to register and deploy a custom model in OpenSearch. You need to provide the model file URL, model configuration details like model type and embedding dimension, and other metadata to register the model. Once registered, you can deploy the model and use it for inference tasks like text embedding or neural search.</td>\n",
       "      <td>{\"inputTokens\": 12282, \"outputTokens\": 92, \"totalTokens\": 12374}</td>\n",
       "      <td>9332</td>\n",
       "      <td>1. Context: The context provides detailed information about registering and deploying models in OpenSearch, including custom models, pretrained models, and models hosted on third-party platforms. It covers the required parameters, configuration options, and examples for each scenario.\\n\\n2. Completeness: The generated answer fully addresses the original question of whether custom models can be run in OpenSearch. It confirms that custom models can be registered and deployed in OpenSearch, and provides the necessary steps and parameters to do so.\\n\\n3. Conciseness: The generated answer is concise and directly addresses the question without redundancy.</td>\n",
       "      <td>3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.038226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>How do I use vector search?</td>\n",
       "      <td>&lt;question_answer&gt;\\nThere is not enough information available to answer this question. The provided context describes what vector search is and how to create vector indexes, but does not provide instructions on how to use vector search.\\n&lt;/question_answer&gt;</td>\n",
       "      <td>There is not enough information available to answer this question. The provided context describes what vector search is and how to create vector indexes, but does not provide instructions on how to use vector search.</td>\n",
       "      <td>{\"inputTokens\": 16947, \"outputTokens\": 53, \"totalTokens\": 17000}</td>\n",
       "      <td>6425</td>\n",
       "      <td>Context:\\n- The context provides an overview of vector search in OpenSearch, including how to create vector indexes, ingest vector data, and perform vector searches using different methods (approximate k-NN, script score k-NN, and Painless extensions).\\n- It covers the different engines (nmslib, Faiss, Lucene) and algorithms (HNSW, IVF) supported for approximate k-NN search, as well as how to choose the right method based on requirements like query latency, query quality, memory limits, and indexing latency.\\n- The context also explains how to generate vector embeddings within OpenSearch using the Neural Search plugin.\\n\\nCompleteness:\\n- The context does not provide instructions on how to actually use vector search once the index is created and data is ingested. It focuses more on the setup and configuration aspects.\\n- Therefore, the generated answer stating that there is not enough information to answer how to use vector search is accurate and complete based on the provided context.\\n\\nConciseness:\\n- The generated answer is concise and to the point, using the fewest words possible to convey that the context lacks instructions for using vector search.\\n\\nBased on the evaluation criteria:</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.051636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initial review of grades from LLM-as-a-Judge\n",
    "\n",
    "llm_results1['score'] = llm_results1['score'].astype('int64')\n",
    "llm_results2['score'] = llm_results2['score'].astype('int64')\n",
    "\n",
    "def calculate_percentage_correct(df, threshold=2):\n",
    "    total_count = len(df)\n",
    "    correct_count = len(df[df['score'] > threshold])\n",
    "    return (correct_count / total_count) * 100\n",
    "\n",
    "percentage_correct1 = calculate_percentage_correct(llm_results1)\n",
    "print(f\"Percentage correct for answer_results1: {percentage_correct1:.2f}%\")\n",
    "\n",
    "percentage_correct2 = calculate_percentage_correct(llm_results2)\n",
    "print(f\"Percentage correct for answer_results2: {percentage_correct2:.2f}%\")\n",
    "\n",
    "# sample a subsection of 3 incorrect responses for answer_results1\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "sample_size1 = 3 if len(llm_results1[(llm_results1['score'] <= 2)])  > 3 else len(llm_results1[(llm_results1['score'] <= 2)])\n",
    "incorrect_rows = llm_results1[(llm_results1['score'] <= 2)].sample(n=sample_size1)\n",
    "incorrect_rows_no_context = incorrect_rows.drop(columns=['retrieved_chunks'])\n",
    "# Convert the dataframe to an HTML table\n",
    "table_html = incorrect_rows_no_context.to_html(index=False, classes='table table-striped')\n",
    "display(HTML(table_html))\n",
    "\n",
    "# sample a subsection of 3 correct responses for answer_results1\n",
    "sample_size2 = 3 if len(llm_results1[(llm_results1['score'] > 2)]) > 3 else len(llm_results1[(llm_results1['score'] > 2)])\n",
    "correct_rows = llm_results1[(llm_results1['score'] > 2)].sample(n=sample_size2)\n",
    "correct_rows_no_context = correct_rows.drop(columns=['retrieved_chunks'])\n",
    "# Convert the dataframe to an HTML table\n",
    "table_html = correct_rows_no_context.to_html(index=False, classes='table table-striped')\n",
    "display(HTML(table_html))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f14b1e-b99d-468f-a574-5b7b44251eac",
   "metadata": {},
   "source": [
    "# Takeaways\n",
    "* If accuracy as evaluated by LLM-as-a-Judge remains similar, but other metrics such as cost and latency improve, then the alternative LLM (e.g. Haiku) is a viable option."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87c58c7",
   "metadata": {},
   "source": [
    "### SCRATCHPAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "110a34cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_job: arn:aws:bedrock:us-east-1:026459568683:evaluation-job/ziqk76cfgk50\n"
     ]
    }
   ],
   "source": [
    "# Bedrock LLM eval example\n",
    "\n",
    "import boto3\n",
    "import random\n",
    "import string\n",
    "\n",
    "bedrock_client = boto3.client('bedrock',region_name=REGION)\n",
    "sagemaker_client = boto3.client('sagemaker',region_name=REGION)\n",
    "\n",
    "# Generate the random string\n",
    "random_string = ''.join(random.choice(string.ascii_letters + string.digits) for _ in range(6)).lower()\n",
    "\n",
    "create_flow_definition_response = sagemaker_client.create_flow_definition(\n",
    "    FlowDefinitionName= f'human-eval-task-{random_string}',\n",
    "    HumanLoopRequestSource={\n",
    "        'AwsManagedHumanLoopRequestSource': 'AWS/Bedrock/Evaluation'\n",
    "    },\n",
    "\n",
    "    HumanLoopConfig={\n",
    "        'WorkteamArn': WORKTEAM_ARN,\n",
    "        'HumanTaskUiArn': f'arn:aws:sagemaker:{REGION}:394669845002:human-task-ui/Evaluation',\n",
    "        'TaskTitle': 'Human review tasks',\n",
    "        'TaskDescription': 'Determine best answer',\n",
    "        'TaskCount': 1,\n",
    "        'TaskAvailabilityLifetimeInSeconds': 864000,\n",
    "        'TaskTimeLimitInSeconds': 3600,\n",
    "        'TaskKeywords': [\n",
    "            'evaluation',\n",
    "        ],\n",
    "        \n",
    "    },\n",
    "    OutputConfig={\n",
    "        'S3OutputPath': f's3://{S3_BUCKET_NAME}/eval',\n",
    "    },\n",
    "    RoleArn=SAGEMAKER_ROLE_ARN,\n",
    "    Tags=[\n",
    "        {\n",
    "            'Key': 'eval',\n",
    "            'Value': 'human-eval'\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "flow_definition = create_flow_definition_response.get('FlowDefinitionArn')\n",
    "\n",
    "\n",
    "\n",
    "create_evaluation_job_response = bedrock_client.create_evaluation_job(\n",
    "    jobName=f'human-eval-{random_string}',\n",
    "    jobDescription=\"Evaluate answer generated with different prompt templates\",\n",
    "    roleArn=SAGEMAKER_ROLE_ARN,\n",
    "    inferenceConfig={\n",
    "        # array of models to be evaluated\n",
    "        \"models\": [\n",
    "            {\n",
    "                \"bedrockModel\": {\n",
    "                    \"modelIdentifier\":f\"arn:aws:bedrock:{REGION}::foundation-model/mistral.mixtral-8x7b-instruct-v0:1\",\n",
    "                    \"inferenceParams\":\"{\\\"temperature\\\":\\\"0.0\\\", \\\"topP\\\":\\\"1\\\", \\\"maxTokenCount\\\":\\\"512\\\"}\"\n",
    "                }\n",
    "            }\n",
    "        \n",
    "            # {\n",
    "            #     \"bedrockModel\": {\n",
    "            #         \"modelIdentifier\":f\"arn:aws:bedrock:{region}::foundation-model/amazon.titan-text-lite-v1\",\n",
    "            #         \"inferenceParams\":\"{\\\"temperature\\\":\\\"0.25\\\", \\\"topP\\\":\\\"1\\\", \\\"maxTokenCount\\\":\\\"256\\\"}\"\n",
    "            #     }\n",
    "\n",
    "            # },\n",
    "            \n",
    "        ]\n",
    "\n",
    "    },\n",
    "    outputDataConfig={\n",
    "        \"s3Uri\":f\"s3://{S3_BUCKET_NAME}/evalresults/\"\n",
    "    },\n",
    "    evaluationConfig={\n",
    "        \"human\": {\n",
    "        \"humanWorkflowConfig\": {\n",
    "            \"flowDefinitionArn\": f\"{flow_definition}\",\n",
    "            \"instructions\": \"Review the generated answers\"\n",
    "        },\n",
    "        \"customMetrics\": [\n",
    "            {\n",
    "                \"name\": \"HumanPreference\",\n",
    "                \"description\": \"human preference\",\n",
    "                \"ratingMethod\": \"IndividualLikertScale\"\n",
    "            }\n",
    "        ],\n",
    "        \"datasetMetricConfigs\": [\n",
    "            {\n",
    "                \"taskType\": \"Generation\",\n",
    "                \"dataset\": {\n",
    "                    \"name\": \"Custom_Dataset1\",\n",
    "                    \"datasetLocation\": {\n",
    "                        \"s3Uri\": f\"s3://{S3_BUCKET_NAME}/eval/data.jsonl\"\n",
    "                    }\n",
    "                },\n",
    "                \"metricNames\": [\n",
    "                  \"HumanPreference\",\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "      }\n",
    "\n",
    "    }\n",
    ")\n",
    "eval_job = create_evaluation_job_response.get('jobArn')\n",
    "print(f'eval_job: {eval_job}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
